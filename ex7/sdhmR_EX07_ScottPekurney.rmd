---
title: "Exercise Title Goes Here"
author: "Your Name Goes Here"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: html_document
---

<!-- These are global options  
       set root directory here 
       NOTE mine is active; yours is commented out
       change the path to reflect your CPU,
       then comment out or delete mine
--> 
```{r global_options, include=FALSE}
knitr::opts_knit$set(root.dir = "~/words/classes/sdmR_ALLversions/sdhmR-V2022.1")
#knitr::opts_knit$set(root.dir = "~/sdhmR-V2022.1")
knitr::opts_chunk$set(warning=FALSE,error=TRUE,message=FALSE)
```

---

## This exercise links to Module 5.1

Submit the completed exercise to us at:

* t.edwards@usu.edu 
* eric_tsakiris@fws.gov  

---

## Context

The data are of the *Pinus edulis* Common piñon, the species you dealt with in Exercise #3 -- #5.  This exercise relies on the dataframe you generated in exercise #6.  Hopefully you saved those combined presence:absence dataframe, with the reduced variables you begin SDHM model construction with, or regrettably you will need to return to exercise #6 and re--build that dataframe.

The goal is to:
* Estimate variables in reduced and full--variable logistic GLM models, significance, and direction of relationship
* Calculate an estimate of model fit
* Build a table of accuracy metrics, and AUC plot
* Provide some bulleted interpretation points
* Plot map products of the:
  * (i) probability; and 
  * (ii) classified distribution model
  * (Save these two maps as **`.img`** files for use later in the course)


Remember, you will have been assigned data for *edulis* having one the following four discrete labels:

* **Seedlings**:  these data indicate spatial locations where seedlings of the tree have been found
* **Mortality**: these data indicate spatial locations where mortality has been observed
* **Persistence**: these data have no observed mortality or seedling at given spatial locations
* **Range**: the total dataset, including all spatial locations of seedlings, mortality, and persistence

---

## The Data

* The dataframe completed in exercise #6.

```{r global option}
#----------Global options---------#
#Setting Paths
path.root <- "D:/OneDrive - University of Vermont/Classes/Spring2022/sdhmR/sdhmR-V2022.1" #Reed Laptop Path
#path.root <- "C:/Users/14842/Documents/SDHM/sdhmR-V2022.1" #Lindsey Path
path.ex <- paste(path.root, "/data/exercise/traindat", sep = "") #Path to mod 2
path.preds <- paste(path.root, '/data/exercise/preds', sep = '')
path.figs <- paste(path.root, "/powerpoints/figures", sep = "") #path to save figs
path.gis <- paste(path.root, "/data/gis_layers", sep = "") #path to gis files

# some libraries
library(raster)	# FXNS: extent, raster, res, rasterize, values, writeRaster, 
#       cellFromXY, extract
library(sf)    	# FXNS: st_as_sf, st_as_sfc, st_bbox, st_convex_hull, st_union
#       st_buffer, st_read, st_write, st_intersection, st_geometry,
#       st_drop_geometry, st_coordinates, st_sf
library(terra)	# FXNS: as.data.frame, rast, vect
library(sp)
library(dplyr)
library(tidyverse)
library(data.table)
library(modeest)
# source course CRSs
setwd(path.root)
getwd()
source("r_code/prjs4_sdhmR.r")
ls(pattern = "prj.") # should be 5 prj.* objects
```
---

## Question #1

* Import and explore data
  * **NOTE**:  intent is not to reduce number of variables; that was completed in exercise #5.  Rather, calculate simple descriptive statistics (mean, sd, n) and boxplots


```{r}
############################
#Question 1: Import and explore the data
load('tr_PERS.Rdata')
class(tr_PERS)
head(tr_PERS)

#attempt to use for() loop
descSTAT <- {}
descSTAT <- as.data.frame(descSTAT)
for(i in 27:length(tr_PERS)){
  mean <- mean(tr_PERS[,i], na.rm = T) #mean returned NA
  NAS <- sum(is.na(tr_PERS[,i])) #checked for number of NAs
  SD <- sd(tr_PERS[,i], na.rm = T) #standard deviation
  N <- nrow(tr_PERS) - sum(is.na(tr_PERS[,i])) #check total N
  rname <- names(tr_PERS[,i])
  stats <- c(rname, mean, NAS, SD, N)
  descSTAT <- rbind(descSTAT, stats)
}

#explore etpt5
mean(tr_PERS$etpt_5.img, na.rm = T) #mean returned NA
sum(is.na(tr_PERS$etpt_5.img)) #checked for number of NAs
sd(tr_PERS$etpt_5.img, na.rm = T) #standard deviation
nrow(tr_PERS) - sum(is.na(tr_PERS$etpt_5.img)) #check total N

#explore etpt6
mean(tr_PERS$etpt_6.img, na.rm = T) #mean returned NA
sum(is.na(tr_PERS$etpt_6.img)) #checked for number of NAs
sd(tr_PERS$etpt_6.img, na.rm = T) #standard deviation
nrow(tr_PERS) - sum(is.na(tr_PERS$etpt_6.img)) #check total N
#explore etpt_sprin
mean(tr_PERS$etpt_sprin.img, na.rm = T) #mean returned NA
sum(is.na(tr_PERS$etpt_sprin.img)) #checked for number of NAs
sd(tr_PERS$etpt_sprin.img, na.rm = T) #standard deviation
nrow(tr_PERS) - sum(is.na(tr_PERS$etpt_sprin.img)) #check total N
#explore mind_yr_ave
mean(tr_PERS$mind_yr_av.img, na.rm = T) #mean returned NA
sum(is.na(tr_PERS$mind_yr_av.img)) #checked for number of NAs
sd(tr_PERS$mind_yr_av.img, na.rm = T) #standard deviation
nrow(tr_PERS) - sum(is.na(tr_PERS$mind_yr_av.img)) #check total N
#explore prec_winte
mean(tr_PERS$prec_winte.img, na.rm = T) #mean returned NA
sum(is.na(tr_PERS$prec_winte.img)) #checked for number of NAs
sd(tr_PERS$prec_winte.img, na.rm = T) #standard deviation
nrow(tr_PERS) - sum(is.na(tr_PERS$prec_winte.img)) #check total N
#explore tave_s_hal
mean(tr_PERS$tave_s_hal.img, na.rm = T) #mean returned NA
sum(is.na(tr_PERS$tave_s_hal.img)) #checked for number of NAs
sd(tr_PERS$tave_s_hal.img, na.rm = T) #standard deviation
nrow(tr_PERS) - sum(is.na(tr_PERS$tave_s_hal.img)) #check total N
#explore tave_sprin
mean(tr_PERS$tave_sprin.img, na.rm = T) #mean returned NA
sum(is.na(tr_PERS$tave_sprin.img)) #checked for number of NAs
sd(tr_PERS$tave_sprin.img, na.rm = T) #standard deviation
nrow(tr_PERS) - sum(is.na(tr_PERS$tave_sprin.img)) #check total N
#explore tmax_summe
mean(tr_PERS$tmax_summe.img, na.rm = T) #mean returned NA
sum(is.na(tr_PERS$tmax_summe.img)) #checked for number of NAs
sd(tr_PERS$tmax_summe.img, na.rm = T) #standard deviation
nrow(tr_PERS) - sum(is.na(tr_PERS$tmax_summe.img)) #check total N


#Boxplots
par(mfrow = c(3, 3))
boxplot(tr_PERS$etpt_5.img ~ tr_PERS$PERS106, xlab = "Presence:Absence", 
        ylab = "etpt5", na.rm = T)
boxplot(tr_PERS$etpt_6.img ~ tr_PERS$PERS106, xlab = "Presence:Absence", 
        ylab = "etpt6", na.rm = T)
boxplot(tr_PERS$etpt_sprin.img ~ tr_PERS$PERS106, xlab = "Presence:Absence", 
        ylab = "etpt_sprin", na.rm = T)
boxplot(tr_PERS$mind_yr_av.img ~ tr_PERS$PERS106, xlab = "Presence:Absence", 
        ylab = "mind_yr_ave", na.rm = T)
boxplot(tr_PERS$prec_winte.img ~ tr_PERS$PERS106, xlab = "Presence:Absence", 
        ylab = "prec_winte", na.rm = T)
boxplot(tr_PERS$tave_s_hal.img ~ tr_PERS$PERS106, xlab = "Presence:Absence", 
        ylab = "tave_s_hal", na.rm = T)
boxplot(tr_PERS$tave_sprin.img ~ tr_PERS$PERS106, xlab = "Presence:Absence", 
        ylab = "tave_sprin", na.rm = T)
boxplot(tr_PERS$tmax_s_hal.img ~ tr_PERS$PERS106, xlab = "Presence:Absence", 
        ylab = "tmax_s_hal", na.rm = T)
boxplot(tr_PERS$tmax_summe.img ~ tr_PERS$PERS106, xlab = "Presence:Absence", 
        ylab = "tmax_summe", na.rm = T)
```



---

## Question #2

* Construct full- and reduced-variable logistic GLM’s
* Determine an estimate of model fit, based on deviance.

```{r}
mod1.LR <- glm(as.factor(PERS106) ~
                 etpt_5.img+etpt_6.img+etpt_sprin.img+mind_yr_av.img+prec_winte.img+tave_s_hal.img+tave_sprin.img+
                 tmax_s_hal.img+tmax_summe.img, data = tr_PERS, family = binomial)
summary(mod1.LR) #everything is sig. or marginal except etpt6

# model 1 fit
mod1.fit <- 100 * (1 - mod1.LR$deviance/mod1.LR$null.deviance) # model fit
mod1.fit  # examine fit
mod1.pred <- predict(mod1.LR, type = "response") # model prediction
head(mod1.pred)
#not a great predictor

#   variable reduction: backwards
mod2.LR <- step(mod1.LR, trace = F) # backwards stepwise variable reduction
mod2.fit <- 100 * (1 - mod2.LR$deviance/mod2.LR$null.deviance)
mod2.fit # model fit

# model 1 v. model 2 fit
100 * (1 - mod1.LR$deviance/mod1.LR$null.deviance)  # fit model 1
100 * (1 - mod2.LR$deviance/mod2.LR$null.deviance)  # fit model 2

# model 2 prediction
mod2.pred <- predict(mod2.LR, type = "response") # model prediction
head(mod2.pred)

# model 1 v. model 2 prediction
head(mod1.pred) # mod 1 prediction
head(mod2.pred) # mod 2 prediction

# model 2 summary
summary(mod2.LR) # reduced model summary 
```

Based on deviance, both the full model and the reduced model had a model fit of ~28%, so not very good.
---

## Question #3

* Calculate accuracy metrics (as in Module 3.2 and 3.3, Analytical Intermission) using:
  * Resubstitution approaches, and
  * A 10-fold cross--validation approach
```{r}
pers <- 'PERS106'
#Resubstitution
mod1.LR.pred <- predict(mod1.LR, type = 'response')
head(mod1.LR.pred)

#10x cross-val
set.seed(1234) # set and save seed if desire replicability of samples
glm.cv10 <- CVbinary(mod1.LR, nfolds = 10, print.details = F) # cross validate model w/10 folds
ls(glm.cv10) # examine crossval object
head(glm.cv10$cvhat) # examine 



# examine resubstitution and cross-validation estimates
head(mod1.LR.pred) # examine resub prediction
head(glm.cv10$cvhat) # examine xval prediction
glm.cvpred <- glm.cv10$cvhat # assign new name to crossval estimates
dat2 <- cbind(pers, tr_PERS[2], mod1.LR.pred, glm.cvpred) # build dataframe
head(dat2, 2) # examine; NOTE will differ each run unless seed is saved 

#set threshold using PresenceAbsence package + calculate model accuratcies
mod.cut <- optimal.thresholds(dat2, opt.methods = c("ObsPrev")) # threshold=PREVALENCE
mod.cut # examine threshold=PREVALENCE

mod1.acc <- presence.absence.accuracy(dat2, threshold = mod.cut$mod1.LR.pred)
tss <- mod1.acc$sensitivity + mod1.acc$specificity - 1 # code TSS metric
mod1.acc <- cbind(mod1.acc[1:7], tss) # bind all metrics
head(mod1.acc) # examine
```
---

## Question #4

* Build 2 prediction maps:
  * A raw probability estimate for each cell in the modelling domain; and
  * A classified map based on the selected threshold from Question #3
  
```{r}
##########################################################################
#Question 4: * Build 2 prediction maps:
#A raw probability estimate for each cell in the modelling domain; and
#A classified map based on the selected threshold from Question #3
#------------------------------------------------------------------------
######## START BUILD RASTER STACK
# build stack of raster layers
setwd(path.ex)
load('pers.bufR.RData')
setwd(path.preds)
preds.list <- list.files(pattern = ".img$") # list of .img files; $ strips extra
preds.list # examine

# loop for stacking rasters
layers <- {} # initialize (empty) list of raster layers
for (i in 1:length(preds.list)) {
  r1 <- crop(raster(preds.list[i]), pers.bufR) # crop pred var raster to buffer
  names(r1) <- strsplit(preds.list[i], "_wgs.img") # assign name to raster
  layers <- c(layers, r1) # add raster to layer of rasters
}
layers # examine raster stack; return is a list of raster layers

# build the raster stack
pers.DOM <- stack(layers) # create a raster stack
pers.DOM # examine stac
######## END BUILD RASTER STACK
################################################################################
setwd(path.gis)
states <- st_read(dsn = ".", layer = "na_states_wgs") # import shapefile

#create a probability model
pers.prob <- predict(mod1.LR, tr_PERS, 
                       type = "response", fun = predict, index = 2, overwrite = T) # prediction raster
pers.prob # examine 

# next reclassify based on threshold mod.cut per above
pers.class <- reclassify(pers.prob, c(0,mod.cut[[2]],0, 
                                         mod.cut[[2]],1,1))
# giggle maps
par(mfrow = c(1, 2))
plot(pers.prob, legend = F, axes = T, main = "Probability Map") # plot probability map
plot(st_geometry(states), add = T, lwd = 1.5) # add state boundaries
plot(pers.class, legend = F, axes = T, main = "Classification Map") # plot classification map
plot(st_geometry(states), add = T, lwd = 1.5) # add state boundaries
par(mfrow = c(1, 1))
```

---

## Question #5

* Save your data as R objects:
  * Accuracy metrics as a dataframe;
  * Classification threshold as a stand--alone scalar
  * Both prediction maps as **`.img`** format
* Save these R objects in a **`.RData`** file

These data will be used again in Module 10, Ensemble Models.

```{r}
setwd(path.ex)
save.image(pers.class,pers.prob,file='ex7maps.img')
save(mod.cut,mod1.acc,pers.class,pers.prob, file = 'ex7.RData')
save.image()
```
---

## The End
---
